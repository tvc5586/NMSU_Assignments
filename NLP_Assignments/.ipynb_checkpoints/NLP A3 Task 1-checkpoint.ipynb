{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62894ccd-83a9-4eac-9a10-9f5fb10e024c",
   "metadata": {},
   "source": [
    "# NMSU CSCI-5435 Assignment 3 Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972881b-fce4-4157-9a9f-793974666f2c",
   "metadata": {},
   "source": [
    "## Relevent Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69de6a1-fa33-471d-8bd3-48baab69de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name:               Tianjie Chen\n",
    "#Email:              tvc5586@nmsu.edu\n",
    "#File Creation Date: Feb/26/2025\n",
    "#Purpose of File:    NMSU CSCI-5435 Assignment 3 Task 1\n",
    "#Last Edit Date:     Feb/27/2025\n",
    "#Last Edit Note:     Re-run experiments\n",
    "#GenAI used:         False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a33049-b0cb-48af-b124-6309c8c8a3ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d050781-ff97-4772-b5e0-03bb8abcf20c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gensim.downloader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100ccdc-21d9-467d-9809-ea4473a016de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3dadd1-2c65-4240-9c3d-e614c8930645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING GPU\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8caabe4-604d-405f-b7c1-26eca7721835",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024  # BATCH SIZE FOR THIS MODEL\n",
    "epochs     = 50   # Number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe99c4-8a28-45d0-94ee-e7e73992a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.downloader.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f72a0-3b05-4f40-b914-754e7454ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"News_Category_Dataset_v2.json\"\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        text = item[\"short_description\"]\n",
    "        label = item[\"category\"]\n",
    "        \n",
    "        X.append(text)\n",
    "        Y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59901017-ba58-44f8-982f-75b242f821be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462a50c-0a48-480a-b1c9-42af5f5b6441",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, temp = [], []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    split_sent = X[i].split(' ')\n",
    "    for word in split_sent:\n",
    "        try:\n",
    "            _.append(word2vec[word])\n",
    "        except:\n",
    "            _.append(np.zeros(300))\n",
    "    _ = np.array(_)\n",
    "    _ = np.mean(_, axis=0)\n",
    "    temp.append(_)\n",
    "    _ = []\n",
    "\n",
    "X = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a95bf4-15b2-4314-a85a-20eaa2b92d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5447b2c-dad9-4ded-909d-0210aa8fce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_encoded = np.zeros((Y.size, Y.max()+1), dtype=int)\n",
    "Y_encoded[np.arange(Y.size), Y] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc33b9d-e3dc-4e54-93d1-ae2e09fb285d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b045c3-e006-42f6-9bad-84751bf3b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fe8c0-4d3b-49e3-b1f5-2577878db344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATASET CLASS FOR DATALOADERS\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data1, data2):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data1[idx]\n",
    "        y = self.data2[idx]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfff80-d041-46c3-9a16-fcbe81f715da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_dataset = Dataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2cfbab-0ef4-4285-9076-6eea94f05a98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2-layer Model and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0bb0d-92e5-4b50-902d-d1c88e3e417a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf6772-b444-42bf-9401-b1c3cd4c948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class Model_2_Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(300, 300)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(300, 100)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 41)\n",
    "        self.act_output = nn.ReLU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee60adf-58da-474d-bd5b-f7627c74a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2l = Model_2_Layer().to(device)\n",
    "model_2l = model_2l.to(device)   # using '.to(device)' to move the model from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fc8ae-c284-4446-a08e-eba1ef74899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(model_2l.parameters(), lr = 0.001)  \n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56194802-2674-4275-8667-ca420cfc9d79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab4f26-f9ff-4ae1-964d-dbb85c02649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE FNN MODEL\n",
    "def trainModel(\n",
    "    train_dataloader, test_dataloader,\n",
    "    X_train, X_test,\n",
    "    epoch,\n",
    "    model\n",
    "):\n",
    "\n",
    "    history_train = []\n",
    "    history_test = []\n",
    "    train_dataloader_len = len(train_dataloader)\n",
    "    test_dataloader_len = len(test_dataloader)\n",
    "    train_len = X_train.shape[0]\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    for epoch in range(epochs):  # loops over the complete dataset multiple times (which is the nummber of epochs)\n",
    "        model.train()     \n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        train_accuracy = 0.0\n",
    "        for i, data in enumerate(train_dataloader, 0):  # loops over complete training dataset once \n",
    "            \n",
    "            inputs, label = data\n",
    "            inputs, label = inputs.float(), label.float()    # convert double values to float\n",
    "            inputs, label = inputs.to(device), label.to(device)   \n",
    "    \n",
    "            model_optim.zero_grad()\n",
    "            output = model(inputs)   # forward pass of model\n",
    "            output = output.to(device)\n",
    "            \n",
    "            loss1 = CEloss(output, label)     # loss calculation\n",
    "            loss1.backward()            # computes the gradient during the backward pass\n",
    "            model_optim.step()   # performs single optimization step\n",
    "    \n",
    "            train_loss += loss1.item()   # adding accuracy values of all batches in an epoch\n",
    "            _, output = torch.max(output, 1)     # storing the index of maximum value in prediction to the variable 'output'\n",
    "            output = output.cpu().detach().numpy()     # loads the variable to cpu and converts it to a numpy array\n",
    "            label = label.cpu().detach().numpy()        \n",
    "            label = np.argmax(label, axis = 1)   # storing the index of maximum value in label to the variable 'label'\n",
    "            train_accuracy += accuracy_score(label, output)  # adding accuracy values of all batches in training dataset in an epoch\n",
    "        \n",
    "        train_loss = train_loss/train_dataloader_len\n",
    "        train_accuracy = train_accuracy/train_dataloader_len  # dividing accuracy by number of batches for training dataset\n",
    "        history_train.append((train_loss, train_accuracy))\n",
    "        \n",
    "        model.eval()     # model evaluation on test dataset\n",
    "        test_loss = 0.0\n",
    "        test_accuracy = 0.0\n",
    "        correct_test = 0\n",
    "        with torch.no_grad():     # disables gradient calculation\n",
    "            for i, data in enumerate(test_dataloader, 0):    # loops over complete test dataset once\n",
    "                \n",
    "                inputs, label = data\n",
    "                inputs, label = inputs.float(), label.float()\n",
    "                inputs, label = inputs.to(device), label.to(device)\n",
    "    \n",
    "                pred = model(inputs)\n",
    "                pred = pred.to(device)\n",
    "                loss2 = CEloss(pred, label)\n",
    "    \n",
    "                test_loss += loss2.item()\n",
    "                _, pred = torch.max(pred, 1)\n",
    "                pred = pred.cpu().detach().numpy()\n",
    "                label = label.cpu().detach().numpy()\n",
    "                label = np.argmax(label, axis = 1)    \n",
    "                test_accuracy += accuracy_score(label, pred)\n",
    "                \n",
    "            test_loss = test_loss/test_dataloader_len\n",
    "            test_accuracy = test_accuracy/test_dataloader_len\n",
    "            history_test.append((test_loss, test_accuracy))\n",
    "        \n",
    "        print(f' Epoch {epoch + 1} '.center(70, '*'))\n",
    "        print(\"Train Loss:\", train_loss, \"\\tTrain Accuracy:\", train_accuracy)\n",
    "        print(\"Test Loss:\", test_loss, \"\\tTest Accuracy:\", test_accuracy)\n",
    "    \n",
    "    print(\"\".center(70, '*'))\n",
    "    print(\"Final test accuracy:\", test_accuracy)\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0975c4-95ac-427e-be5b-1b44a8bd1850",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Train 2-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6c1b5-bc93-4e78-9443-d798c3af91b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2l_test_acc = trainModel(\n",
    "    train_dataloader, test_dataloader,\n",
    "    X_train, X_test,\n",
    "    epochs,\n",
    "    model_2l\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2348e-f88e-4c57-aa3e-8e24c368fc14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Compare with different number of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72848f91-cafc-4e7b-b0c2-cc888a499a74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497819d7-8bc1-467c-8650-70acf4c03b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class Model_1_Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden2 = nn.Linear(300, 100)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 41)\n",
    "        self.act_output = nn.ReLU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6328f7-caa2-46c1-bff8-dac814150117",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1l = Model_1_Layer().to(device)\n",
    "model_1l = model_1l.to(device)   # using '.to(device)' to move the model from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb084f00-2785-45b1-8796-780105bf1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(model_1l.parameters(), lr = 0.001)  \n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2518f-91a8-4277-95b1-256c6f670d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_1l_test_acc = trainModel(\n",
    "    train_dataloader, test_dataloader,\n",
    "    X_train, X_test,\n",
    "    epochs,\n",
    "    model_1l\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efdc261-3c5a-408a-a87d-48fac4980c89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c0a62-8f08-48a8-adf5-22b3b6e04e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class Model_3_Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(300, 300)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(300, 300)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.hidden3 = nn.Linear(300, 100)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(100, 41)\n",
    "        self.act_output = nn.ReLU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act3(self.hidden3(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803d35f-f7af-448b-9ff7-123f6c8bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3l = Model_3_Layer().to(device)\n",
    "model_3l = model_3l.to(device)   # using '.to(device)' to move the model from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea40d1d-1773-41f5-a173-842246c2dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(model_3l.parameters(), lr = 0.001)  \n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38b86b-cfaa-44ec-998a-23a0d8fcd50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_3l_test_acc = trainModel(\n",
    "    train_dataloader, test_dataloader,\n",
    "    X_train, X_test,\n",
    "    epochs,\n",
    "    model_3l\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3dac0e-51f7-4c36-87bf-1f068474a671",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Comparison Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9e6ed-7272-4662-ab08-1b46ba0ee7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"Accuracy Comparison:\\n\n",
    "        1 Layer:\\t{model_1l_test_acc}\\n\n",
    "        2 Layers:\\t{model_2l_test_acc}\\n\n",
    "        3 Lyaers:\\t{model_3l_test_acc}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc58746-f68b-4e6a-986b-7a78572928b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Compare with different activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba84b0-6163-4dac-8bf0-9119b59a3515",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2 Layers with ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02279e46-d37b-4bb5-8478-ab347f10c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class Model_2_Layer_ELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(300, 300)\n",
    "        self.hidden2 = nn.Linear(300, 100)\n",
    "        self.act = nn.ELU()\n",
    "        self.output = nn.Linear(100, 41)\n",
    "        self.act_output = nn.ReLU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden1(x))\n",
    "        x = self.act(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc258d55-3372-44d6-8f07-fd64f07941a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2l_ELU = Model_2_Layer_ELU().to(device)\n",
    "model_2l_ELU = model_2l_ELU.to(device)   # using '.to(device)' to move the model from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f571af-8e60-466f-a29e-295c6b471e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(model_2l_ELU.parameters(), lr = 0.001)  \n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66af9a4-1817-4c43-b753-c9a7b56144ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2l_elu_test_acc = trainModel(\n",
    "    train_dataloader, test_dataloader,\n",
    "    X_train, X_test,\n",
    "    epochs,\n",
    "    model_2l_ELU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daeb800-761f-4f7a-8f6d-469b192add0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2 Layers with Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2bbaf-b01a-47be-854a-9b02637ee5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class Model_2_Layer_Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(300, 300)\n",
    "        self.hidden2 = nn.Linear(300, 100)\n",
    "        self.act = nn.SiLU()\n",
    "        self.output = nn.Linear(100, 41)\n",
    "        self.act_output = nn.ReLU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden1(x))\n",
    "        x = self.act(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd031c-6792-4d14-b78a-b6effad133f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2l_Swish = Model_2_Layer_Swish().to(device)\n",
    "model_2l_Swish = model_2l_Swish.to(device)   # using '.to(device)' to move the model from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a81dd-0c0e-4663-adc7-9b725652787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim=torch.optim.Adam(model_2l_Swish.parameters(), lr = 0.001)  \n",
    "CEloss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc2eef-1699-433a-b14c-970de702e925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2l_swish_test_acc = trainModel(\n",
    "    train_dataloader, test_dataloader,\n",
    "    X_train, X_test,\n",
    "    epochs,\n",
    "    model_2l_Swish\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0aa6e-b3a9-4d34-aad3-49afcd0f5b77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Comparison Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa2ba6-6e2c-4022-9000-b235279a031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"Accuracy Comparison:\\n\n",
    "        2 Layers ReLU:\\t{model_2l_test_acc}\\n\n",
    "        2 Layers ELU:\\t{model_2l_elu_test_acc}\\n\n",
    "        2 Lyaers Swish:\\t{model_2l_swish_test_acc}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0dcd30-14ce-465d-9bb2-5ee499deaf4f",
   "metadata": {},
   "source": [
    "ELU gives the best performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
