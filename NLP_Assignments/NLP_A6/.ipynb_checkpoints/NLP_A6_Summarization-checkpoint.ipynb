{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b278812c-311f-465b-926c-2f8455dcb9d9",
   "metadata": {},
   "source": [
    "# NMSU CSCI-5435 Assignment 6 Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195aff86-38a2-4463-ba8f-06f4d23d8298",
   "metadata": {},
   "source": [
    "## Relevent Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0b27d-70d0-40cb-aaca-bb59dfd3ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name:               Tianjie Chen\n",
    "#Email:              tvc5586@nmsu.edu\n",
    "#File Creation Date: Apr/23/2025\n",
    "#Purpose of File:    NMSU CSCI-5435 Assignment 6 Task 1\n",
    "#Last Edit Date:     Apr/23/2025\n",
    "#Last Edit Note:     File creation\n",
    "#GenAI used:         False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609df9d4-7790-421c-bb44-2cd4a65e1a26",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e77cae-bb75-49a4-a70f-582e968050e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea1f012-25d5-4952-ac40-fbc762e7373c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ec608d-e5c3-4d8e-828d-b97a742d0560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# USING GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8db10c4-f9b1-45ec-8f98-0396cfa2ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"news_summary.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d614720-b490-4350-9711-82594ceb1e5a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8aa36e-5a0e-4934-96c5-3618eea882a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10dace9-9ed7-4237-ac35-62fa08435e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a11e7c-7bcd-4ff8-83a0-dfd3bcf25b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=list(examples[\"headlines\"]), max_length=128, truncation=True)\n",
    "\n",
    "    processed_data = []\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        _ = {\"text\": inputs[i], \"input_ids\": model_inputs[i].ids, \"labels\": labels[i].ids}\n",
    "        processed_data.append(_)\n",
    "        \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0383ff3-29a8-4f5a-b369-3cd8347b0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = preprocess_function(train)\n",
    "tokenized_test  = preprocess_function(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9e5c03-4e17-43e6-99da-13fa9b22158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'summarize: Hollywood actress Kate Winslet has joined the cast of \\'Titanic\\' director James Cameron\\'s upcoming films in the \\'Avatar\\' franchise, making this their first venture together after 20 years of Titanic\\'s release. Cameron said, \"Kate and I have been looking for something to do together...since our collaboration on Titanic...I can\\'t wait to see her bring the character of Ronal to life.\"', 'input_ids': [21603, 10, 8426, 15676, 11845, 4871, 7, 1655, 65, 3311, 8, 4061, 13, 3, 31, 382, 155, 9, 2532, 31, 2090, 2549, 18501, 31, 7, 3, 4685, 4852, 16, 8, 3, 31, 188, 900, 2046, 31, 7884, 6, 492, 48, 70, 166, 6086, 544, 227, 460, 203, 13, 13622, 447, 31, 7, 1576, 5, 18501, 243, 6, 96, 439, 342, 11, 27, 43, 118, 479, 21, 424, 12, 103, 544, 233, 27296, 69, 3561, 30, 13622, 447, 233, 196, 54, 31, 17, 1749, 12, 217, 160, 830, 8, 1848, 13, 10297, 138, 12, 280, 535, 1], 'labels': [11845, 4871, 7, 1655, 12, 161, 28, 13622, 447, 13762, 227, 460, 203, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b2cadf-c4a8-4142-92b5-27451fa1889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c25c81-5f86-40a8-8a3a-78aff8386e5f",
   "metadata": {},
   "source": [
    "## Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c15bd4da-4882-4f9f-b83e-1c144ffadabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90f6de7-a9a6-44f3-bb27-dc38616beb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5857a4-4aec-4274-b74e-b8d3dec0d732",
   "metadata": {},
   "source": [
    "## Define & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c255411e-20c2-4ce4-8291-56d23df37cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c44e242-4608-4993-b573-8408b305b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24371/360464422.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2460' max='2460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2460/2460 15:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.253300</td>\n",
       "      <td>1.699746</td>\n",
       "      <td>0.490400</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.447600</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>15.585800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.921900</td>\n",
       "      <td>1.614432</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>15.670400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.849400</td>\n",
       "      <td>1.581562</td>\n",
       "      <td>0.507800</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.465200</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>15.682500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.822500</td>\n",
       "      <td>1.573169</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.466300</td>\n",
       "      <td>15.676200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2460, training_loss=1.9315718239885036, metrics={'train_runtime': 914.2379, 'train_samples_per_second': 344.418, 'train_steps_per_second': 2.691, 'total_flos': 1.0530844066185216e+16, 'train_loss': 1.9315718239885036, 'epoch': 4.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"NLP_A6\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e24a06-69c8-4525-bf9d-e64bc88c4b0c",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a501bfcf-0f21-4135-9224-15741304110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a8744c-17c2-45c5-a78f-820b06a1b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "inputs = inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9997d8bb-1c1a-4f00-bba7-d8c9600a4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(inputs, max_new_tokens=100, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5051404-cefa-4233-b3e0-49e78e46d03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inflation Reduction Act lowers prescription drug costs, health care costs'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
